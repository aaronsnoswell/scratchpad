{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# LQR Demo\n",
    "\n",
    "A demonstration of a simple linear quadratic regulator for ostacle avoidance in 2D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Request high dpi, inline figures\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqr(A, B, Q, R):\n",
    "    \"\"\"Solve for the optimal infinite-horizon LQR gain matrix\n",
    "    \n",
    "    Args:\n",
    "        A (numpy array): MxM Linear state dynamics matrix\n",
    "        B (numpy array): MxN Linear control dynamics matrix\n",
    "        Q (numpy array): MxM Quadratic state cost matrix\n",
    "        R (numpy array): NxN Quadratic control cost matrix\n",
    "    \n",
    "    Returns:\n",
    "        (numpy array): NxM Infinite horizon discrete LQR gain matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check matrix dimensions\n",
    "    assert A.shape[0] == A.shape[1], \"A matrix is not square\"\n",
    "    assert Q.shape[0] == Q.shape[1], \"Q matrix is not square\"\n",
    "    assert R.shape[0] == R.shape[1], \"R matrix is not square\"\n",
    "    \n",
    "    num_states = A.shape[0]\n",
    "    num_controls = B.shape[1]\n",
    "\n",
    "    assert B.shape[0] == num_states, \"B matrix is incorrect shape\"\n",
    "    assert Q.shape[0] == num_states, \"Q matrix is incorrect size\"\n",
    "    assert R.shape[0] == num_controls, \"R matrix is incorrect size\"\n",
    "    \n",
    "    # Solve the Discrete Algebraic Ricatti Equation\n",
    "    M = scipy.linalg.solve_discrete_are(A, B, Q, R)\n",
    "\n",
    "    # K = ((B'MB + R) ** -1) * (B'MA)\n",
    "    return np.dot(\n",
    "        scipy.linalg.inv(\n",
    "            np.dot(np.dot(B.T, M), B) +\n",
    "            R\n",
    "        ),\n",
    "        np.dot(np.dot(B.T, M), A)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple LQR system\n",
    "\n",
    "# M State dimensions\n",
    "num_states = 4\n",
    "x, vx, y, vy = range(num_states)\n",
    "\n",
    "# N Action dimensions\n",
    "num_actions = 2\n",
    "ax, ay = range(num_actions)\n",
    "\n",
    "dt = 0.1\n",
    "goal_state = np.array([4, 0, 0, 0])\n",
    "\n",
    "# MxM Linear Dynamical System state matrix\n",
    "A = np.array([\n",
    "    [1, dt,  0,  0],\n",
    "    [0,  1,  0,  0],\n",
    "    [0,  0,  1, dt],\n",
    "    [0,  0,  0,  1],\n",
    "])\n",
    "\n",
    "# MxN LDS control matrix\n",
    "B = np.array([\n",
    "    [0,  0],\n",
    "    [dt, 0],\n",
    "    [0,  0],\n",
    "    [0, dt],\n",
    "])\n",
    "\n",
    "# Mx1 Constant state offset\n",
    "C = -goal_state.T\n",
    "\n",
    "# Nx1 Contant control/acceleration offset\n",
    "D = np.array([[0, -9.81]]).T\n",
    "\n",
    "# MxM Quadratic state cost matrix\n",
    "Q = np.eye(num_states)\n",
    "\n",
    "# NxN Quadratic control cost matrix\n",
    "R = np.eye(num_actions)\n",
    "\n",
    "def integrate(x0, pi, num_steps=500):\n",
    "    \"\"\"Inteagrate a policy and start state into a trajectory\"\"\"\n",
    "    traj = np.array([x0.copy() + C])\n",
    "    for step in range(num_steps):\n",
    "        x = traj[-1, :]\n",
    "        u = pi(x)\n",
    "        x_prime = A.dot(x) + B.dot(u + np.squeeze(D))\n",
    "        traj = np.vstack((traj, x_prime))\n",
    "    return traj - C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s0 = np.zeros(num_states)\n",
    "s0[vy] = 1\n",
    "s0[vx] = 1\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "# Plot free-fall trajectory\n",
    "traj_ff = integrate(s0, lambda s: np.zeros(num_actions))\n",
    "plt.plot(\n",
    "    traj_ff[:, x],\n",
    "    traj_ff[:, y],\n",
    "    'C0.-',\n",
    "    label='Zero control'\n",
    ")\n",
    "\n",
    "# Plot conservative trajectory\n",
    "k_agg = lqr(A, B, Q, 0.1 * R)\n",
    "traj_agg = integrate(s0, lambda s: -k_agg.dot(s) - np.squeeze(D))\n",
    "plt.plot(\n",
    "    traj_agg[:, x],\n",
    "    traj_agg[:, y],\n",
    "    'C1.-',\n",
    "    label='Conservative control'\n",
    ")\n",
    "\n",
    "# Plot aggressive trajectory\n",
    "k_agg = lqr(A, B, Q, 100 * R)\n",
    "traj_agg = integrate(s0, lambda s: -k_agg.dot(s) - np.squeeze(D))\n",
    "plt.plot(\n",
    "    traj_agg[:, x],\n",
    "    traj_agg[:, y],\n",
    "    'C2.-',\n",
    "    label='Aggressive control'\n",
    ")\n",
    "\n",
    "# Plot goal\n",
    "plt.plot(*goal_state[[x, y]], 'C3x', label='Goal')\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Trajectory\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim((-1, 5))\n",
    "plt.ylim((-3, 3))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
